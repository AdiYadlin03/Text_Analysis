{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 - Text Analysis\n",
    "An explanation this assignment could be found in the .pdf explanation document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Materials to review for this assignment\n",
    "<h4>From Moodle:</h4> \n",
    "<h5><u>Review the notebooks regarding the following python topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Working with strings</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Text Analysis</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Hebrew text analysis tools (tokenizer, wordnet)</b> (moodle example)<br/>\n",
    "&#x2714; <b>(brief review) All previous notebooks</b><br/>\n",
    "</div> \n",
    "<h5><u>Review the presentations regarding the following topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Text Analysis</b> (lecture presentation)<br/>\n",
    "&#x2714; <b>(brief review) All other presentations</b><br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external modules (packages). <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# ------------- visualizations:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "import sklearn\n",
    "from sklearn import preprocessing, metrics, pipeline, model_selection, feature_extraction \n",
    "from sklearn import naive_bayes, linear_model, svm, neural_network, neighbors, tree\n",
    "from sklearn import decomposition, cluster\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# added:\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ----------------- output and visualizations: \n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text analysis and String manipulation imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# --------- Text analysis and Hebrew text analysis imports:\n",
    "# vectorizers:\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# regular expressions:\n",
    "import re\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - WordNet (for Hebrew)\n",
    "Note: the WordNet is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install Wordnet (for Hebrew) use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net installation:\n",
    "\n",
    "# unmark if you want to use and need to install\n",
    "# !pip install wn\n",
    "# !python -m wn download omw-he:1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net import:\n",
    "\n",
    "# unmark if you want to use:\n",
    "import wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - hebrew_tokenizer (Tokenizer for Hebrew)\n",
    "Note: the hebrew_tokenizer is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install hebrew_tokenizer use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer installation:\n",
    "\n",
    "# unmark if you want to use and need to install:\n",
    "# !pip install hebrew_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adi/Downloads/assignment5-text_analysis\n"
     ]
    }
   ],
   "source": [
    "# Hebrew tokenizer import:\n",
    "\n",
    "# unmark if you want to use:\n",
    "import hebrew_tokenizer as ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input files\n",
    "Reading input files for train annotated corpus (raw text data) corpus and for the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'annotated_corpus_for_train.csv'\n",
    "test_filename  = 'corpus_for_test.csv'\n",
    "df_train = pd.read_csv(train_filename, index_col=None, encoding='utf-8')\n",
    "df_test = pd.read_csv(test_filename, index_col=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>כשחבר הזמין אותי לחול, לא באמת חשבתי שזה יקרה,...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>לפני שהתגייסתי לצבא עשיתי כל מני מיונים ליחידו...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>מאז שהתחילו הלימודים חלומו של כל סטודנט זה הפנ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>כשהייתי ילד, מטוסים היה הדבר שהכי ריתק אותי. ב...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‏הייתי מדריכה בכפר נוער ומתאם הכפר היינו צריכי...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>לפני כ3 חודשים טסתי לרומא למשך שבוע. טסתי במטו...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>אני כבר שנתיים נשוי והשנה אני ואישתי סוף סוף י...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>השנה התחלנו שיפוץ בדירה שלנו בתל אביב. הדירה ה...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story gender\n",
       "0  כשחבר הזמין אותי לחול, לא באמת חשבתי שזה יקרה,...      m\n",
       "1  לפני שהתגייסתי לצבא עשיתי כל מני מיונים ליחידו...      m\n",
       "2  מאז שהתחילו הלימודים חלומו של כל סטודנט זה הפנ...      f\n",
       "3  כשהייתי ילד, מטוסים היה הדבר שהכי ריתק אותי. ב...      m\n",
       "4  ‏הייתי מדריכה בכפר נוער ומתאם הכפר היינו צריכי...      f\n",
       "5  לפני כ3 חודשים טסתי לרומא למשך שבוע. טסתי במטו...      f\n",
       "6  אני כבר שנתיים נשוי והשנה אני ואישתי סוף סוף י...      m\n",
       "7  השנה התחלנו שיפוץ בדירה שלנו בתל אביב. הדירה ה...      f"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(753, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(8)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_example_id</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>כל קיץ אני והמשפחה נוסעים לארצות הברית לוס אנג...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>הגעתי לשירות המדינה אחרי שנתיים כפעיל בתנועת \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>אחת האהבות הגדולות שלי אלו הכלבים שלי ושל אישת...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_example_id                                              story\n",
       "0                0  כל קיץ אני והמשפחה נוסעים לארצות הברית לוס אנג...\n",
       "1                1  הגעתי לשירות המדינה אחרי שנתיים כפעיל בתנועת \"...\n",
       "2                2  אחת האהבות הגדולות שלי אלו הכלבים שלי ושל אישת..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(323, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your implementation:\n",
    "Write your code solution in the following code-cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes the text and removes numbers, leading and trailing spaces and replaces multiple whitespaces with a single space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_text(text):\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a hebrew text and returns a list of tokens using the hebrew tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(raw_text):\n",
    "    token = ht.tokenize(raw_text)\n",
    "    tokens_list = list(filter(lambda x: (x[0] == 'HEBREW'),token))\n",
    "    tokens_list = [tuple[1] for tuple in tokens_list]\n",
    "    return tokens_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gender column needs to become numeric in order to process it with a ML model, so I added a new column named 'gender_num'.\n",
    "Also used the function handle text for preproccesing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as many code cells as you need\n",
    "# YOUR CODE HERE\n",
    "\n",
    "def handle_train(df):\n",
    "    # preprocess the text\n",
    "    df['story'] = df ['story'].apply(handle_text)\n",
    "    \n",
    "    # fit and transform the gender column to numeric values\n",
    "    le = LabelEncoder()\n",
    "    df['gender_num'] = le.fit_transform(df['gender'])\n",
    "    \n",
    "    # got X_train and y_train\n",
    "    X_train = df.story\n",
    "    y_train = df.gender_num\n",
    "    \n",
    "    return X_train, y_train\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I wanted to try the models with the default values and only using vectorizer with a simple tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_simple_prediction(models_list, X, y):\n",
    "    # Define the scoring metric - f1_macro as defined in the assignment\n",
    "    scoring = make_scorer(f1_score, average='macro')\n",
    "    \n",
    "    # Define the vectorizers to try without parameters \n",
    "    vectorizers = [\n",
    "        ('tfidf', TfidfVectorizer(tokenizer=my_tokenizer)),\n",
    "        ('count', CountVectorizer(tokenizer=my_tokenizer))\n",
    "    ]\n",
    "    for model_name, model in models_list.items():\n",
    "        for vec_name, vectorizer in vectorizers:\n",
    "            # Create the feature vectors with the vectorizer\n",
    "            X_features = vectorizer.fit_transform(X)\n",
    "            \n",
    "            model.fit(X_features, y)\n",
    "            \n",
    "            # Calculate the mean F1-macro score from cross-validation scores\n",
    "            cv_scores = cross_val_score(model, X_features, y, cv=10, scoring=scoring)\n",
    "            mean_score = cv_scores.mean()\n",
    "            \n",
    "            print(f\"Model: {model_name}, Vectorizer: {vec_name}\")\n",
    "            print(\"Mean F1-macro Score:\", mean_score)\n",
    "            print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: linearSVC, Vectorizer: tfidf\n",
      "Mean F1-macro Score: 0.5172040607797049\n",
      "-------------------------------------------\n",
      "Model: linearSVC, Vectorizer: count\n",
      "Mean F1-macro Score: 0.6807491133071919\n",
      "-------------------------------------------\n",
      "Model: sgd, Vectorizer: tfidf\n",
      "Mean F1-macro Score: 0.6055382908898974\n",
      "-------------------------------------------\n",
      "Model: sgd, Vectorizer: count\n",
      "Mean F1-macro Score: 0.6507572160552088\n",
      "-------------------------------------------\n",
      "Model: neuralNetwork, Vectorizer: tfidf\n",
      "Mean F1-macro Score: 0.5380789701232455\n",
      "-------------------------------------------\n",
      "Model: neuralNetwork, Vectorizer: count\n",
      "Mean F1-macro Score: 0.5711470722558112\n",
      "-------------------------------------------\n",
      "Model: perceptron, Vectorizer: tfidf\n",
      "Mean F1-macro Score: 0.6463593076340446\n",
      "-------------------------------------------\n",
      "Model: perceptron, Vectorizer: count\n",
      "Mean F1-macro Score: 0.6603325055499101\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models_list = {\n",
    "    'linearSVC':LinearSVC(),\n",
    "    'sgd': SGDClassifier(),\n",
    "    'neuralNetwork':MLPClassifier(),\n",
    "    'perceptron':Perceptron()\n",
    "}\n",
    "X_train, y_train = handle_train(df_train)\n",
    "perform_simple_prediction(models_list, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I wanted to try with normalizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_prediction_normalizing(models_list, X, y):\n",
    "    # Define the scoring metric - f1_macro as defined in the assignment\n",
    "    scoring = make_scorer(f1_score, average='macro')\n",
    "    \n",
    "    # Define the vectorizers to try without parameters \n",
    "    vectorizers = [\n",
    "        ('tfidf', TfidfVectorizer(tokenizer=my_tokenizer)),\n",
    "        ('count', CountVectorizer(tokenizer=my_tokenizer))\n",
    "    ]\n",
    "    for model_name, model in models_list.items():\n",
    "        for vec_name, vectorizer in vectorizers:\n",
    "            # Create the feature vectors with the vectorizer\n",
    "            X_features = vectorizer.fit_transform(X)\n",
    "            \n",
    "            # Apply normalization to the feature vectors\n",
    "            norm = preprocessing.Normalizer(norm='l2')\n",
    "            X_features = norm.transform(X_features)\n",
    "            \n",
    "            model.fit(X_features, y)\n",
    "            \n",
    "            # Calculate the mean F1-macro score from cross-validation scores\n",
    "            cv_scores = cross_val_score(model, X_features, y, cv=10, scoring=scoring)\n",
    "            mean_score = cv_scores.mean()\n",
    "            \n",
    "            print(f\"Model: {model_name}, Vectorizer: {vec_name}\")\n",
    "            print(\"Mean F1-macro Score:\", mean_score)\n",
    "            print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: linearSVC, Vectorizer: tfidf\n",
      "Mean F1-macro Score: 0.5172040607797049\n",
      "-------------------------------------------\n",
      "Model: linearSVC, Vectorizer: count\n",
      "Mean F1-macro Score: 0.5963274583191005\n",
      "-------------------------------------------\n",
      "Model: sgd, Vectorizer: tfidf\n",
      "Mean F1-macro Score: 0.6039466869915285\n",
      "-------------------------------------------\n",
      "Model: sgd, Vectorizer: count\n",
      "Mean F1-macro Score: 0.6582065183853958\n",
      "-------------------------------------------\n",
      "Model: neuralNetwork, Vectorizer: tfidf\n",
      "Mean F1-macro Score: 0.539164367284224\n",
      "-------------------------------------------\n",
      "Model: neuralNetwork, Vectorizer: count\n",
      "Mean F1-macro Score: 0.5557472744448927\n",
      "-------------------------------------------\n",
      "Model: perceptron, Vectorizer: tfidf\n",
      "Mean F1-macro Score: 0.6463593076340446\n",
      "-------------------------------------------\n",
      "Model: perceptron, Vectorizer: count\n",
      "Mean F1-macro Score: 0.6157001778567275\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models_list = {\n",
    "    'linearSVC':LinearSVC(),\n",
    "    'sgd': SGDClassifier(),\n",
    "    'neuralNetwork':MLPClassifier(),\n",
    "    'perceptron':Perceptron()\n",
    "}\n",
    "X_train, y_train = handle_train(df_train)\n",
    "perform_prediction_normalizing(models_list, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I wanted to try with scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_prediction_normalizing_scaling(models_list, X, y):\n",
    "    # Define the scoring metric - f1_macro as defined in the assignment\n",
    "    scoring = make_scorer(f1_score, average='macro')\n",
    "    \n",
    "    # Define the vectorizers to try without parameters \n",
    "    vectorizers = [\n",
    "        ('tfidf', TfidfVectorizer(tokenizer=my_tokenizer)),\n",
    "        ('count', CountVectorizer(tokenizer=my_tokenizer))\n",
    "    ]\n",
    "    for model_name, model in models_list.items():\n",
    "        for vec_name, vectorizer in vectorizers:\n",
    "            # Create the feature vectors with the vectorizer\n",
    "            X_features = vectorizer.fit_transform(X)\n",
    "            \n",
    "            # Apply normalization to the feature vectors\n",
    "            norm = preprocessing.Normalizer(norm='l2')\n",
    "            X_features = norm.transform(X_features)\n",
    "            \n",
    "            # Scale the features with StandardScaler\n",
    "            scaler = StandardScaler(with_mean=False)\n",
    "            X_features = scaler.fit_transform(X_features)\n",
    "            \n",
    "            model.fit(X_features, y)\n",
    "            \n",
    "            # Calculate the mean F1-macro score from cross-validation scores\n",
    "            cv_scores = cross_val_score(model, X_features, y, cv=10, scoring=scoring)\n",
    "            mean_score = cv_scores.mean()\n",
    "            \n",
    "            print(f\"Model: {model_name}, Vectorizer: {vec_name}\")\n",
    "            print(\"Mean F1-macro Score:\", mean_score)\n",
    "            print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: linearSVC, Vectorizer: tfidf\n",
      "Mean F1-macro Score: 0.4870485971329684\n",
      "-------------------------------------------\n",
      "Model: linearSVC, Vectorizer: count\n",
      "Mean F1-macro Score: 0.4870485971329684\n",
      "-------------------------------------------\n",
      "Model: sgd, Vectorizer: tfidf\n",
      "Mean F1-macro Score: 0.6212006028260516\n",
      "-------------------------------------------\n",
      "Model: sgd, Vectorizer: count\n",
      "Mean F1-macro Score: 0.6075454932122977\n",
      "-------------------------------------------\n",
      "Model: neuralNetwork, Vectorizer: tfidf\n",
      "Mean F1-macro Score: 0.6282657345470678\n",
      "-------------------------------------------\n",
      "Model: neuralNetwork, Vectorizer: count\n",
      "Mean F1-macro Score: 0.5480836626579164\n",
      "-------------------------------------------\n",
      "Model: perceptron, Vectorizer: tfidf\n",
      "Mean F1-macro Score: 0.6276585458543527\n",
      "-------------------------------------------\n",
      "Model: perceptron, Vectorizer: count\n",
      "Mean F1-macro Score: 0.6267061405664227\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models_list = {\n",
    "    'linearSVC':LinearSVC(),\n",
    "    'sgd': SGDClassifier(),\n",
    "    'neuralNetwork':MLPClassifier(),\n",
    "    'perceptron':Perceptron()\n",
    "}\n",
    "X_train, y_train = handle_train(df_train)\n",
    "perform_prediction_normalizing_scaling(models_list, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function performs a grid search to find the best combination of model, vectorizer, normalization,\n",
    "and parameters based on the F1-macro score. It uses cross-validation to evaluate the performance of each\n",
    "combination. The best model is then fitted on the entire dataset, and cross-validation is performed again\n",
    "to obtain the final evaluation scores. The function returns the best model, vectorizer, normalization, and\n",
    "scaler, which can be used for making predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(models_list, params_list, X, y):\n",
    "    # Define the scoring metric - f1_macro as defined in the assignment\n",
    "    scoring = make_scorer(f1_score, average='macro')\n",
    "\n",
    "    best_mean_score = 0\n",
    "    best_model = None\n",
    "    best_vectorizer = None\n",
    "    best_normalization = None\n",
    "    best_params = None\n",
    "\n",
    "    # Define the vectorizers to try with parameters \n",
    "    vectorizers = [\n",
    "        ('tfidf', TfidfVectorizer(ngram_range=(1, 1), min_df=10, max_df=100, max_features=10000, tokenizer=my_tokenizer)),\n",
    "        ('count', CountVectorizer(ngram_range=(1, 1), min_df=9, max_df=100, max_features=5000, tokenizer=my_tokenizer))\n",
    "    ]\n",
    "\n",
    "    # Define the normalization method to try\n",
    "    norms = ['l1', 'l2']\n",
    "\n",
    "    # Go through all the models, normalization methods and possible parameters to find the best combination\n",
    "    for model_name, model in models_list.items():\n",
    "        # Parameters to try for the model\n",
    "        params = params_list[model_name]\n",
    "        for vec_name, vectorizer in vectorizers:\n",
    "            for current_norm in norms:\n",
    "                # Create the feature vectors with the vectorizer\n",
    "                X_features = vectorizer.fit_transform(X)\n",
    "\n",
    "                # Apply normalization to the feature vectors\n",
    "                norm = preprocessing.Normalizer(norm=current_norm)\n",
    "                X_features = norm.transform(X_features)\n",
    "\n",
    "                # Scale the features with StandardScaler\n",
    "                scaler = StandardScaler(with_mean=False)\n",
    "                X_features = scaler.fit_transform(X_features)\n",
    "\n",
    "                # Create the grid search object\n",
    "                grid_search = GridSearchCV(model, params, cv=10, scoring=scoring)\n",
    "\n",
    "                # Fit the grid search to the processed data\n",
    "                grid_search.fit(X_features, y)\n",
    "\n",
    "                # Calculate the mean F1-macro score from cross-validation scores\n",
    "                cv_scores = cross_val_score(grid_search.best_estimator_, X_features, y, cv=10, scoring=scoring)\n",
    "                mean_score = cv_scores.mean()\n",
    "\n",
    "                # Check if it's better than the current best model and save the info if it is\n",
    "                if mean_score > best_mean_score:\n",
    "                    best_mean_score = mean_score\n",
    "                    best_model = model_name\n",
    "                    best_vectorizer = vec_name\n",
    "                    best_normalization = current_norm\n",
    "                    best_params = grid_search.best_params_\n",
    "\n",
    "                # Print the best parameters and score for the current model\n",
    "                print(f\"Model: {model_name}, Vectorizer: {vec_name}, Normalizer: {current_norm}\")\n",
    "                print(\"Best Parameters:\", grid_search.best_params_)\n",
    "                print(\"Mean F1-macro Score:\", mean_score)\n",
    "                print(\"-------------------------------------------\")\n",
    "\n",
    "    # Use the best model, vectorizer, normalization, and parameters for final fitting\n",
    "    best_model_obj = models_list[best_model]\n",
    "    best_vectorizer_obj = [vec[1] for vec in vectorizers if vec[0] == best_vectorizer][0]\n",
    "    best_normalization_obj = best_normalization\n",
    "\n",
    "    # Create the feature vectors with the best vectorizer\n",
    "    X_features = best_vectorizer_obj.fit_transform(X)\n",
    "    # Apply normalization to the feature vectors\n",
    "    X_features = preprocessing.normalize(X_features, norm=best_normalization_obj)\n",
    "    # Scale the features\n",
    "    scale = StandardScaler(with_mean=False)\n",
    "    X_features = scale.fit_transform(X_features)\n",
    "\n",
    "    # Fit the best model on the entire dataset\n",
    "    best_model_obj.fit(X_features, y)\n",
    "\n",
    "    # Print the best model info\n",
    "    print(\"Best Model:\")\n",
    "    print(\"Model:\", best_model)\n",
    "    print(\"Vectorizer:\", best_vectorizer)\n",
    "    print(\"Normalization:\", best_normalization)\n",
    "    print(\"Best Mean F1-macro Score on Cross-Validation:\", best_mean_score)\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "\n",
    "    # Return all that is needed to do prediction on the test set\n",
    "    return best_model_obj, best_vectorizer_obj, best_normalization_obj, scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = {\n",
    "    'linearSVC':LinearSVC(),\n",
    "    'sgd': SGDClassifier(),\n",
    "    'neuralNetwork':MLPClassifier(),\n",
    "    'perceptron':Perceptron()\n",
    "}\n",
    "\n",
    "params_list = {\n",
    "    'linearSVC': {'C': [0.1, 1, 10]},\n",
    "    'sgd': {'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "                         'max_iter': [1000, 2000, 3000],\n",
    "                         'penalty': ['l1', 'l2', 'elasticnet']\n",
    "    },\n",
    "    'neuralNetwork': {\n",
    "        'hidden_layer_sizes': [(100,), (100, 50, 25)],\n",
    "        'activation': ['relu', 'logistic', 'tanh'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'max_iter': [100, 200, 500]\n",
    "    },\n",
    "    'perceptron': {\n",
    "        'alpha': [0.1, 0.01, 0.001],\n",
    "        'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "        'eta0': [0.1, 0.01, 0.001]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do preprocessing on the data and start grid search. The function return the best model, normalizer and vectorizer and the scaler that was used. Then this will be used to do prediction on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: linearSVC, Vectorizer: tfidf, Normalizer: l1\n",
      "Best Parameters: {'C': 0.1}\n",
      "Mean F1-macro Score: 0.6504050840414332\n",
      "-------------------------------------------\n",
      "Model: linearSVC, Vectorizer: tfidf, Normalizer: l2\n",
      "Best Parameters: {'C': 10}\n",
      "Mean F1-macro Score: 0.6598949762923876\n",
      "-------------------------------------------\n",
      "Model: linearSVC, Vectorizer: count, Normalizer: l1\n",
      "Best Parameters: {'C': 0.1}\n",
      "Mean F1-macro Score: 0.6576900637952947\n",
      "-------------------------------------------\n",
      "Model: linearSVC, Vectorizer: count, Normalizer: l2\n",
      "Best Parameters: {'C': 0.1}\n",
      "Mean F1-macro Score: 0.6580873788559604\n",
      "-------------------------------------------\n",
      "Model: sgd, Vectorizer: tfidf, Normalizer: l1\n",
      "Best Parameters: {'alpha': 0.0001, 'max_iter': 3000, 'penalty': 'l2'}\n",
      "Mean F1-macro Score: 0.642455510980789\n",
      "-------------------------------------------\n",
      "Model: sgd, Vectorizer: tfidf, Normalizer: l2\n",
      "Best Parameters: {'alpha': 0.0001, 'max_iter': 3000, 'penalty': 'l2'}\n",
      "Mean F1-macro Score: 0.6484768432351967\n",
      "-------------------------------------------\n",
      "Model: sgd, Vectorizer: count, Normalizer: l1\n",
      "Best Parameters: {'alpha': 0.1, 'max_iter': 3000, 'penalty': 'elasticnet'}\n",
      "Mean F1-macro Score: 0.6297782554933662\n",
      "-------------------------------------------\n",
      "Model: sgd, Vectorizer: count, Normalizer: l2\n",
      "Best Parameters: {'alpha': 0.1, 'max_iter': 1000, 'penalty': 'elasticnet'}\n",
      "Mean F1-macro Score: 0.6466033231610503\n",
      "-------------------------------------------\n",
      "Model: neuralNetwork, Vectorizer: tfidf, Normalizer: l1\n",
      "Best Parameters: {'activation': 'logistic', 'hidden_layer_sizes': (100, 50, 25), 'max_iter': 100, 'solver': 'adam'}\n",
      "Mean F1-macro Score: 0.6759784106374354\n",
      "-------------------------------------------\n",
      "Model: neuralNetwork, Vectorizer: tfidf, Normalizer: l2\n",
      "Best Parameters: {'activation': 'logistic', 'hidden_layer_sizes': (100, 50, 25), 'max_iter': 500, 'solver': 'adam'}\n",
      "Mean F1-macro Score: 0.6794551472293493\n",
      "-------------------------------------------\n",
      "Model: neuralNetwork, Vectorizer: count, Normalizer: l1\n",
      "Best Parameters: {'activation': 'logistic', 'hidden_layer_sizes': (100, 50, 25), 'max_iter': 500, 'solver': 'adam'}\n",
      "Mean F1-macro Score: 0.6513410803983662\n",
      "-------------------------------------------\n",
      "Model: neuralNetwork, Vectorizer: count, Normalizer: l2\n",
      "Best Parameters: {'activation': 'logistic', 'hidden_layer_sizes': (100, 50, 25), 'max_iter': 200, 'solver': 'adam'}\n",
      "Mean F1-macro Score: 0.6645407692619142\n",
      "-------------------------------------------\n",
      "Model: perceptron, Vectorizer: tfidf, Normalizer: l1\n",
      "Best Parameters: {'alpha': 0.001, 'eta0': 0.01, 'penalty': 'l1'}\n",
      "Mean F1-macro Score: 0.6704544975587696\n",
      "-------------------------------------------\n",
      "Model: perceptron, Vectorizer: tfidf, Normalizer: l2\n",
      "Best Parameters: {'alpha': 0.1, 'eta0': 0.1, 'penalty': None}\n",
      "Mean F1-macro Score: 0.6698998491648909\n",
      "-------------------------------------------\n",
      "Model: perceptron, Vectorizer: count, Normalizer: l1\n",
      "Best Parameters: {'alpha': 0.001, 'eta0': 0.1, 'penalty': 'l1'}\n",
      "Mean F1-macro Score: 0.6695234728036582\n",
      "-------------------------------------------\n",
      "Model: perceptron, Vectorizer: count, Normalizer: l2\n",
      "Best Parameters: {'alpha': 0.001, 'eta0': 0.001, 'penalty': 'l2'}\n",
      "Mean F1-macro Score: 0.6643632796730811\n",
      "-------------------------------------------\n",
      "Best Model:\n",
      "Model: neuralNetwork\n",
      "Vectorizer: tfidf\n",
      "Normalization: l2\n",
      "Best Mean F1-macro Score on Cross-Validation: 0.6794551472293493\n",
      "Best Parameters: {'activation': 'logistic', 'hidden_layer_sizes': (100, 50, 25), 'max_iter': 500, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = handle_train(df_train)\n",
    "best_model, best_vectorizer, best_normalization, scaler = perform_grid_search(models_list, params_list, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the best model I got was- LinearSVC with count vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro mean: 0.6845119071830548\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = handle_train(df_train)\n",
    "scoring = make_scorer(f1_score, average='macro')\n",
    "\n",
    "best_model = LinearSVC()\n",
    "vectorizer = CountVectorizer(tokenizer= my_tokenizer, max_features=10000)\n",
    "# Create the feature vectors with the vectorizer\n",
    "X_features = vectorizer.fit_transform(X_train)\n",
    "            \n",
    "best_model.fit(X_features, y_train)\n",
    "            \n",
    "# Calculate the mean F1-macro score from cross-validation scores\n",
    "cv_scores = cross_val_score(best_model, X_features, y_train, cv=10, scoring=scoring)\n",
    "mean_score = cv_scores.mean()\n",
    "print(\"f1_macro mean:\", mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the confusion matrix for the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>0</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Female  Male\n",
       "Female     177     1\n",
       "Male         0   575"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_train = best_model.predict(X_features)\n",
    "pd.DataFrame(confusion_matrix(y_pred = predicted_train, y_true = y_train), index = ['Female', 'Male'], columns = ['Female', 'Male'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the test set stories. Then do vectorizing, normalizing and scaling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['story'] = df_test['story'].apply(handle_text)\n",
    "\n",
    "X_test = df_test.story\n",
    "\n",
    "X_test_features = vectorizer.transform(X_test)\n",
    "#X_test_normalized = preprocessing.normalize(X_test_features, norm=best_normalization)\n",
    "#X_test_scaled = scaler.transform(X_test_normalized)\n",
    "\n",
    "# Predict labels for the test set\n",
    "predicted_test = best_model.predict(X_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_example_id</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_example_id predicted_category\n",
       "0                0                  m\n",
       "1                1                  m\n",
       "2                2                  m\n",
       "3                3                  m\n",
       "4                4                  f"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_categories = ['m' if pred == 1 else 'f' for pred in predicted_test]\n",
    "\n",
    "# Create a DataFrame with the test example IDs and predicted categories\n",
    "df_predicted = pd.DataFrame({'test_example_id': df_test['test_example_id'],\n",
    "                               'predicted_category': predicted_categories})\n",
    "df_predicted.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_example_id</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>318</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>319</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>320</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>321</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>322</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_example_id predicted_category\n",
       "318              318                  m\n",
       "319              319                  m\n",
       "320              320                  m\n",
       "321              321                  m\n",
       "322              322                  m"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to see that the percentage of men is close to what it was in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m    249\n",
       "f     74\n",
       "Name: predicted_category, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.patches.Wedge at 0x7fe56c033610>,\n",
       "  <matplotlib.patches.Wedge at 0x7fe56cb45eb0>],\n",
       " [Text(-0.8271706738210322, 0.7251128714693044, 'm'),\n",
       "  Text(0.8271706059310621, -0.7251129489146086, 'f')],\n",
       " [Text(-0.4511840039023811, 0.3955161117105296, '77.1%'),\n",
       "  Text(0.4511839668714883, -0.3955161539534228, '22.9%')])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-1.105256255561613,\n",
       " 1.1002502978838864,\n",
       " -1.1050675889958914,\n",
       " 1.1045804475229066)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize\n",
    "gender_counts = df_predicted['predicted_category'].value_counts()\n",
    "gender_counts\n",
    "labels = gender_counts.index.tolist()\n",
    "sizes = gender_counts.values.tolist()\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv (optional)\n",
    "After you're done save your output to the 'classification_results.csv' csv file.<br/>\n",
    "We assume that the dataframe with your results contain the following columns:\n",
    "* column 1 (left column): 'test_example_id'  - the same id associated to each of the test stories to be predicted.\n",
    "* column 2 (right column): 'predicted_category' - the predicted gender value for each of the associated story. \n",
    "\n",
    "Assuming your predicted values are in the `df_predicted` dataframe, you should save you're results as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.to_csv('classification_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
